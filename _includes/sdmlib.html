<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="sdmlib">sdmlib<a class="anchor-link" href="#sdmlib">&#182;</a></h1><p><code>sdmlib</code> is a simple Python library providing an implementation of SDM that is intended for use with <code>numpy</code> arrays. I wrote this library for personal use while writing my undergraduate thesis in Neuroscience.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Overview">Overview<a class="anchor-link" href="#Overview">&#182;</a></h1><p>Sparse Distributed Memory (SDM) is a technique for simulating computer memory with significantly more storage than is actually possible. Modern computer use $64$-bit memory, but SDM allows us to simulate $1000$-bit memory (or more!) by distributing the operations of reading and writing over a small subset of randomly sampled addresses.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Computer-Memory">Computer Memory<a class="anchor-link" href="#Computer-Memory">&#182;</a></h1><p>You can locate a house on a street using, for example, a $3$-digit combination of the digits $0$ through $9$. This gives you $10^3 = 1000$ possible addresses. Maybe your friend Robin lives at address $831$.</p>
<p>Similarly, you can specify a location in <em>computer memory</em> using a 64-digit combination of the binary digits ("bits") $0$ and $1$. This gives you $2^{64} = 18,446,744,073,709,551,616$ possible memory addresses to choose from. (In reality we do not use all of these addresses, but the principle still holds). We use these addresses to store data. Like addresses, data are stored in the form of $0$s and $1$s, and are usually $64$ bits long (just like street addresses).</p>
<h1 id="Motivation">Motivation<a class="anchor-link" href="#Motivation">&#182;</a></h1><p>SDM was originally developed by Pentti Kanerva as a mathematical model for human long-term memory. Kanerva noted that high-dimensional spaces have some properties in common with human long-term memory. For example, similar memories can be 'nearby' in the same sense that points in high-dimensional space can be 'nearby'. Furthermore, two random memories tend to be unrelated just like two random points in high-dimensional space tend to be far apart. For Kanerva, a sufficiently high number of dimensions begins at least in the hundreds, if not in the thousands.</p>
<p>The simplest high-dimensional space is the binary space $\{0, 1 \}^N$. This space has $N$ dimensions, where each dimension can <em>only</em> take on the value $0$ or $1$. On a $64$-bit computer, every possible address is in $\{0, 1 \}^{64}$.</p>
<p>This space is a good candidate for our mathematical model of human long-term memory because:</p>
<ol>
<li>it is high-dimensional</li>
<li>it is "simple" (only two values)</li>
<li>it can hypothetically be implemented on a digital computer</li>
</ol>
<h1 id="The-Problem">The Problem<a class="anchor-link" href="#The-Problem">&#182;</a></h1><p>The possibility of implementing a model of human memory on a computer is exciting. However, even modern computers that use $64$-bit addresses are not sufficiently 'high-dimensional' for the properties Kanerva was interested in. We are interested in having, for example, $1000$ bit memory addresses. Sadly, this would require $2^{1000}$ locations to store data in our computer and our universe only have $2^{265}$ atoms, so we will run out of atoms before we can construct such a computer.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Solution-to-the-Problem">Solution to the Problem<a class="anchor-link" href="#Solution-to-the-Problem">&#182;</a></h1><p>To solve this problem, Kanerva suggests only implementing a small, randomly sampled number of <em>hard addresses</em> - actual locations in computer memory corresponding to a point in high-dimensional space. We use $M$ to denote the number of hard addresses to implement. $M$ is often small, like $10^6$ (small relative to $2^N$).</p>
<p>If we randomly pick an address from $\{ 0, 1 \}^N$, we are extremely unlikely to pick an address that has a corresponding hard address. In fact, the odds are</p>
$$
\frac{M}{2^N}
$$<p>which, if we take $M=10^6$ and $N=1000$ (common values used in SDM), the odds are approximately $9.3 \times 10^{-296}$.</p>
<p>Let's arrange our hard addresses in an $M \times N$ matrix where each row is a hard address. We can call this matrix $A$.</p>
$$
A = \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \dots &amp; 1 \\
0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \dots &amp; 1 \\
1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 \dots &amp; 1 \\
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \dots &amp; 1 \\
\vdots &amp; &amp; &amp; &amp; &amp; \vdots \\
0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 \dots &amp; 1 \\
\end{bmatrix}
$$<p>Imagine trying to write to an $N$-bit address called $x$. It is unlikely that $x$ is a row of $A$. How, then, can we write to this address? We instead pick hard addresses that are 'close' to $x$. In this case, two addresses are close if the <em>Hamming distance</em> between them is below some threshold $d$.</p>
<p>The Hamming distance between two binary strings of equal length is the number of places where their bits do not match. For example, the Hamming distance between $1001 \; 1111$ and $1011 \; 1110$ is $2$.</p>
<p>We go through each row $i$ in $A$. If the Hamming distance between $x$ $A_i$ is smaller than $d$, then we consider that address to be 'nearby'.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can make a vector $h$ of length $M$ to keep track of the Hamming distance between each row of $A$ and our desired address $x$. We can make a similar vector $y$ that is $1$ where $h &lt; d$ and $0$ otherwise.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="{{site.url}}/assets/sdm1.drawio.png"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To recap: we have a matrix $A$ of addresses. It has $M$ rows and $N$ columns, corresponding to the $M$ hard addresses and the $N$ bits of each address. Given an $N$-bit address $x$ that we would like to access, we construct a vector $y$. If a row $i$ of $A$ has a Hamming distance to $x$ that is smaller than $d$, we set $y_i$ to $1$ and otherwise set it to $0$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How do we write to memory? Let's say we have some data $w$ that we want to write. $w$ is a binary vector of length $U$. In normal computer memory, we pick a single address $x$ and overwrite the contents of that memory with $w$. However, in our new formulation, we have <em>multiple</em> addresses in $A$ that are considered nearby. We do not want to simply replace the contents of all of the nearby addresses with $w$. Why is this a bad idea? Because it's possible that some of those addresses are close to $x$ but also close to some other address $x'$, although $x$ and $x'$ may not themselves be close. We do not want to destroy information that was stored at previous times by just overwriting it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Instead, we have a memory matrix $C$ of shape $M \times U$ that stores <em>counters</em>. For each element in $y_i$ of $y$, if the $y_i = 1$, then we will write $C_i$. For each bit $j$ from $1$ to $U$, if $w_j=1$, then we increment the $c_{ij}$. If $w_j$ is a $0$, then we decrement $C_{ij}$. The process of writing to memory becomes <strong>distributed</strong> across multiple addresses.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="{{site.url}}/assets/sdm2.drawio.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How do we read from memory? Each row of $C$ contains $U$ counters, some of which may be positive and some of which may be negative. If a counter $C_{ij}$ is very positive, then mostly $1$s have been written to that counter. If a counter $C_{ij}$ is very negative, then mostly $0$s have been written to that counter. Let's say we have a memory address $x$ and we would like to read the data stored at that address. Like writing to memory, this address is almost certainly not represented in $A$. Therefore, we find all addresses in $A$ that are nearby to $x$ and create our vector $y$ representing which addresses are nearby. For every address in $A$ that is nearby, we take the corresponding row in $C$ and add them all together element-wise. We call this sum $s$, a vector of length $U$. For each bit position $j$ from $1$ to $U$, if more $1$s have been written to that position over every nearby address than $0$s, then $s_j$ will be positive. If more $0$s have been written to that position over every nearby address than $1$s, then $s_j$ will be negative. Therefore, we can threshold $s$ around $0$ to convert $s$ a binary vector $z$ representing the "average" binary vector stored across nearby addresses:
$$
z = \begin{cases} 1 &amp; s &gt; 0 \\ 0 &amp; s \leq 0  \end{cases}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="{{site.url}}/assets/sdm3.drawio.png" alt=""></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using a vector $y$ to indicate whether or not an address in $A$ is nearby to $x$ is useful if we want to describe the operations of reading and writing to memory using matrix operations. However, I will not cover that approach here for several reasons:</p>
<ol>
<li>It can become notationally heavy with the use of Hadamard products</li>
<li>The actual matrices used are sparse, so naive implementations can a long time to run (unless something like a <code>scipy.sparse.csr_matrix</code> is used)</li>
<li>We can take advantage of <code>numpy</code>'s broadcasting semantics and advanced indexing to perform equivalent operations quickly.</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below I show how one might implement SDM using <code>numpy</code>.</p>
<p>Let's use an object-oriented design in Python for this implementation. We will use one class to represent an instance of SDM. What kind of information do we need to specify an instance of SDM?</p>
<table>
<thead><tr>
<th style="text-align:center">Parameter</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>N</code></td>
<td style="text-align:center">Length of addresses in bits</td>
</tr>
<tr>
<td style="text-align:center"><code>M</code></td>
<td style="text-align:center">Number of hard addresses</td>
</tr>
<tr>
<td style="text-align:center"><code>U</code></td>
<td style="text-align:center">Length of data in bits</td>
</tr>
<tr>
<td style="text-align:center"><code>d</code></td>
<td style="text-align:center">Hamming radius of addresses considered "near" for reading and writing.</td>
</tr>
</tbody>
</table>
<p>Some things that may also be useful include a <code>seed</code>, since the addresses that we pick to generate $A$ are randomly selected from $\{ 0, 1 \}^N$ so being able to set the random seed ensures the same $A$ gets generated.</p>
<p>We will also need the class to have an address matrix $A$ and a counter matrix $C$. The following <code>__init__</code> method captures this information:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">d</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">U</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Technically speaking, the variables $N$ and $M$ do not need to be stored as parameters of the class, but storing them this way makes for easy accessibility and extensibility.</p>
<p>Next, we cover the operation of writing. In order to determine the Hamming distance between $w$ and a row of $A$, we can do</p>
$$
x \text{ xor } A_i
$$<p>to get a vector of length $N$ which is $1$ where the bits of $x$ and $A_i$ differ, and is $0$ where they are the same. We can then sum the elements of this vector to get the Hamming distance. We can also take advantage of <code>numpy</code>'s broadasting semantics to vectorize this operation.</p>
<p>We can use <code>numpy.where</code> in place of a vector $y$ to generate and index set of rows where the Hamming distance is smaller than our predefined threshold $d$.</p>
<p>In order to add a $+1$ to rows of $C$ when bit $j$ of $w$ is a $1$ and add a $-1$ to rows of $C$ when bit $j$ of $w$ is a $0$, we can do
$$
C_i \gets C_i + 2w-1
$$
again taking advantage of <code>numpy</code>'s broadcasting semantics to vectorize this operation.</p>
<p>Putting all this together gives us our <code>write</code> method:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">h</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">y</span><span class="p">]</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">w</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here, <code>h</code> is a vector of length $M$. Instead of being a vector of $1$s and $0$s, <code>y</code> here is just a vector of indices (rows) of <code>A</code> that are sufficiently close to <code>x</code>. We can then use <code>y</code> to index into <code>C</code> using advanced indexing and use <code>numpy</code>'s broadcasting semantics to modify each row of $C$ in the same way (adding or subtracting $1$).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we cover the operation of reading. We use the same code to generate our vector <code>y</code>. We can then easily sum along the columns of <code>C</code> indexed by <code>y</code> to generate <code>s</code>, and then threshold <code>s</code> to generate <code>z</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">h</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="k">return</span> <span class="n">z</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Putting everything together, we get the implementation of <code>sdmlib</code> that is available on PyPi and <a href="github.com/avandekleut/sdmlib">github</a>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="k">class</span> <span class="nc">Memory</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">T</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;d and T cannot both be None.&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Optimality conditions found by Kanerva for uniformly</span>
                <span class="c1"># distributed addresses where z is a function that takes a</span>
                <span class="c1"># probability and returns a z score.</span>
                <span class="n">d</span> <span class="o">=</span> <span class="n">N</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">M</span><span class="o">*</span><span class="n">T</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mf">3.</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">d</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">U</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">write</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">h</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">y</span><span class="p">]</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">w</span>

    <span class="k">def</span> <span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">h</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">[</span><span class="n">y</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">s</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is a toy example of generating random data and storing it in the memory, then retrieving it and comparing it to the original data:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sdmlib</span> <span class="kn">import</span> <span class="n">Memory</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">U</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">addresses</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">data</span>      <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">U</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="n">mem</span> <span class="o">=</span> <span class="n">Memory</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> <span class="n">U</span><span class="o">=</span><span class="n">U</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">mem</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">addresses</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>

<span class="n">error</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    <span class="n">error</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">!=</span> <span class="n">mem</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">addresses</span><span class="p">[</span><span class="n">t</span><span class="p">]))</span><span class="o">/</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Reconstruction error: {100*error:.2f}%&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Reconstruction error: 0.68%
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Final-note">Final note<a class="anchor-link" href="#Final-note">&#182;</a></h1><p>I have included an extra parameter called <code>T</code> in my implementation. This is a variable indicating the number of data to be written to memory. Sometimes this value is known in advance. If the bits of the addresses $x$ and data $w$ are identically and independently uniformly distributed, then there is an optimal value for the threshold $d$ that maximizes the <em>recall fidelity</em> of the memory (how closely retrieved values $z$ match written inputs $x$ once all the data has been written to memory).</p>
<p>Kanerva shows that the optimal probability of activating any particular hard address is given by 
$$
p = \frac{1}{\sqrt[3]{2MT}}
$$</p>
<p>The process randomly generating hard addresses in $A$ one bit at a time can be modelled as a Bernoulli process with $N$ trials, where we have equal probability of choosing a $0$ or a $1$. If we want to model the distribution of Hamming distances, we get a binomial distribution with a mean $\mu = N/2$ and variance $\sigma^2 = N/4$. For large $N$ (by assumption, $N$ is at least in the hundreds or thousands) we can make a normal approximation to the binomial distribution.</p>
<p>We can then, for any given desired probability of activation $p$, derive the Hamming distance $d$ such that the probability of a random address matching another random address in $A$ is
$$
d = \frac{N}{2} + z \left( \frac{1}{\sqrt[3]{2MT}} \right) \sqrt{\frac{N}{4}}
$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>where
$$
z \left( \frac{1}{\sqrt[3]{2MT}} \right)
$$
is the $z$-score for the optimal probability derived by Kanerva.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For more reading, I highly recommend Kanerva's book on the topic.</p>

</div>
</div>
</div>
 

